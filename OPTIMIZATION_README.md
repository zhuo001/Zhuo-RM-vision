# æ¨¡å‹ä¼˜åŒ–ä¸Dockeréƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ONNX Runtime + OpenVINOä¼˜åŒ–YOLOv8æ¨ç†æ€§èƒ½ï¼Œç‰¹åˆ«é€‚é…**AMD 780Mæ ¸æ˜¾**ã€‚

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ¨ç†å¼•æ“å¯¹æ¯”](#æ¨ç†å¼•æ“å¯¹æ¯”)
3. [AMD 780Mä¼˜åŒ–æ–¹æ¡ˆ](#amd-780mä¼˜åŒ–æ–¹æ¡ˆæ¨è)
4. [NVIDIA GPUæ–¹æ¡ˆ](#nvidia-gpuæ–¹æ¡ˆä»…ä¾›å‚è€ƒ)
5. [Dockeréƒ¨ç½²](#dockeréƒ¨ç½²)
6. [æ€§èƒ½åŸºå‡†æµ‹è¯•](#æ€§èƒ½åŸºå‡†æµ‹è¯•)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆé€‰æ‹©

| ç¡¬ä»¶å¹³å° | æ¨èæ–¹æ¡ˆ | é¢„æœŸåŠ é€Ÿ |
|---------|---------|---------|
| **AMD 780Mæ ¸æ˜¾** | ONNXRuntime + OpenVINO | 1.5-2x |
| AMD CPU | ONNXRuntime CPU | 1.2-1.5x |
| NVIDIA GPU | PyTorch (CUDA) | åŸºå‡† |
| NVIDIA GPU | TensorRT | 2-4x |

### AMD 780Mç”¨æˆ·ï¼ˆæ¨èï¼‰

```bash
# 1. å®‰è£…ä¾èµ–
pip install onnx onnxruntime onnxruntime-openvino

# 2. å¯¼å‡ºONNXæ¨¡å‹ï¼ˆFP16é‡åŒ–ï¼‰
python tools/export_to_onnx.py --model yolov8n.pt --fp16

# 3. ä½¿ç”¨OpenVINOæ¨ç†
python person_detect.py --engine onnx-openvino --benchmark
```

---

## ğŸ” æ¨ç†å¼•æ“å¯¹æ¯”

### 1. PyTorchï¼ˆé»˜è®¤ï¼‰

**ä¼˜ç‚¹:**
- âœ… é›¶é…ç½®ï¼Œå¼€ç®±å³ç”¨
- âœ… ç²¾åº¦æœ€é«˜ï¼ˆFP32ï¼‰
- âœ… æ”¯æŒæ‰€æœ‰ç¡¬ä»¶

**ç¼ºç‚¹:**
- âŒ é€Ÿåº¦è¾ƒæ…¢
- âŒ æ¨¡å‹ä½“ç§¯å¤§

**ä½¿ç”¨æ–¹æ³•:**
```bash
python person_detect.py --engine pytorch --benchmark
```

### 2. ONNX Runtime (CPU)

**ä¼˜ç‚¹:**
- âœ… è·¨å¹³å°å…¼å®¹æ€§å¥½
- âœ… æ¯”PyTorchå¿«20-50%
- âœ… æ¨¡å‹ä½“ç§¯æ›´å°

**ç¼ºç‚¹:**
- âŒ é¦–æ¬¡è¿è¡Œéœ€å¯¼å‡ºONNX
- âŒ ä¸æ”¯æŒåŠ¨æ€æ¨¡å‹ä¿®æ”¹

**ä½¿ç”¨æ–¹æ³•:**
```bash
# å¯¼å‡ºONNX
python tools/export_to_onnx.py --model yolov8n.pt --fp16

# æ¨ç†
python person_detect.py --engine onnx --benchmark
```

### 3. ONNX Runtime + OpenVINOï¼ˆAMD 780Mæ¨èï¼‰â­

**ä¼˜ç‚¹:**
- âœ… **AMD 780Mæ ¸æ˜¾åŠ é€Ÿ**
- âœ… æ¯”PyTorchå¿«50-100%
- âœ… æ”¯æŒFP16é‡åŒ–
- âœ… CPU/GPUè‡ªåŠ¨é€‰æ‹©

**ç¼ºç‚¹:**
- âŒ éœ€è¦é¢å¤–å®‰è£…OpenVINOæ”¯æŒ

**ä½¿ç”¨æ–¹æ³•:**
```bash
# å®‰è£…OpenVINOæ‰§è¡Œæä¾›å™¨
pip install onnxruntime-openvino

# å¯¼å‡ºONNXï¼ˆFP16ï¼‰
python tools/export_to_onnx.py --model yolov8n.pt --fp16

# ä½¿ç”¨OpenVINOæ¨ç†
python person_detect.py --engine onnx-openvino --benchmark
```

### 4. TensorRTï¼ˆä»…NVIDIA GPUï¼‰

**ä¼˜ç‚¹:**
- âœ… NVIDIA GPUæè‡´ä¼˜åŒ–
- âœ… 2-4å€åŠ é€Ÿ
- âœ… æ”¯æŒFP16/INT8é‡åŒ–

**ç¼ºç‚¹:**
- âŒ **ä»…æ”¯æŒNVIDIA GPU**
- âŒ **AMD 780Mæ— æ³•ä½¿ç”¨**
- âŒ ç¼–è¯‘æ—¶é—´é•¿

---

## ğŸ¯ AMD 780Mä¼˜åŒ–æ–¹æ¡ˆï¼ˆæ¨èï¼‰

### æ­¥éª¤1: å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–
pip install ultralytics opencv-python numpy

# ONNXæ”¯æŒ
pip install onnx onnxruntime

# OpenVINOæ‰§è¡Œæä¾›å™¨ï¼ˆAMD 780MåŠ é€Ÿï¼‰
pip install onnxruntime-openvino
```

### æ­¥éª¤2: å¯¼å‡ºONNXæ¨¡å‹

```bash
# FP16é‡åŒ–ï¼ˆæ¨èï¼Œæ¨¡å‹ä½“ç§¯å‡åŠï¼Œé€Ÿåº¦æ›´å¿«ï¼‰
python tools/export_to_onnx.py --model yolov8n.pt --fp16

# FP32ï¼ˆç²¾åº¦æœ€é«˜ï¼‰
python tools/export_to_onnx.py --model yolov8n.pt

# æŸ¥çœ‹å¯¼å‡ºç»“æœ
ls -lh yolov8n.onnx
```

**å¯¼å‡ºå‚æ•°è¯´æ˜:**
- `--model`: è¾“å…¥çš„.ptæ¨¡å‹è·¯å¾„
- `--fp16`: ä½¿ç”¨FP16é‡åŒ–ï¼ˆæ¨èï¼‰
- `--output`: è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
- `--imgsz`: è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆé»˜è®¤640ï¼‰

### æ­¥éª¤3: è¿è¡Œæ¨ç†

```bash
# ä½¿ç”¨OpenVINOæ‰§è¡Œæä¾›å™¨ï¼ˆAMD 780Mä¼˜åŒ–ï¼‰
python person_detect.py --engine onnx-openvino --benchmark

# å¦‚æœOpenVINOä¸å¯ç”¨ï¼Œè‡ªåŠ¨å›é€€åˆ°CPU
python person_detect.py --engine onnx --benchmark

# æŸ¥çœ‹å¸®åŠ©
python person_detect.py --help
```

**æ¨ç†å‚æ•°è¯´æ˜:**
- `--engine`: æ¨ç†å¼•æ“ï¼ˆpytorch/onnx/onnx-openvinoï¼‰
- `--model`: æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤yolov8n.ptï¼‰
- `--conf`: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.55ï¼‰
- `--iou`: NMS IOUé˜ˆå€¼ï¼ˆé»˜è®¤0.45ï¼‰
- `--benchmark`: æ˜¾ç¤ºFPSæ€§èƒ½ç»Ÿè®¡

### æ­¥éª¤4: æ€§èƒ½å¯¹æ¯”

è¿è¡Œä¸‰ç§æ¨¡å¼å¹¶è®°å½•FPSï¼š

```bash
# PyTorchåŸºå‡†
python person_detect.py --engine pytorch --benchmark

# ONNX CPU
python person_detect.py --engine onnx --benchmark

# ONNX OpenVINOï¼ˆAMD 780Mï¼‰
python person_detect.py --engine onnx-openvino --benchmark
```

---

## ğŸ–¥ï¸ NVIDIA GPUæ–¹æ¡ˆï¼ˆä»…ä¾›å‚è€ƒï¼‰

> âš ï¸ **é‡è¦**: AMD 780Mç”¨æˆ·æ— æ³•ä½¿ç”¨æ­¤æ–¹æ¡ˆï¼Œè¯·ä½¿ç”¨ä¸Šè¿°OpenVINOæ–¹æ¡ˆ

### TensorRTä¼˜åŒ–æµç¨‹

```bash
# 1. å¯¼å‡ºONNX
python tools/export_to_onnx.py --model yolov8n.pt --fp16 --no-dynamic

# 2. æ„å»ºTensorRTå¼•æ“ï¼ˆéœ€è¦NVIDIA GPUï¼‰
python tools/onnx_to_tensorrt.py --onnx yolov8n.onnx --fp16

# 3. ä½¿ç”¨TensorRTæ¨ç†ï¼ˆéœ€è¦å®ç°ä¸“ç”¨æ¨ç†è„šæœ¬ï¼‰
# æ³¨æ„: person_detect.pyå½“å‰ä¸æ”¯æŒTensorRTå¼•æ“åŠ è½½
```

### ç¯å¢ƒè¦æ±‚

- NVIDIA GPUï¼ˆè®¡ç®—èƒ½åŠ› >= 6.1ï¼‰
- CUDA Toolkit >= 11.8
- TensorRT >= 8.6
- nvidia-container-toolkitï¼ˆDockerï¼‰

---

## ğŸ³ Dockeréƒ¨ç½²

### AMD 780Mæ–¹æ¡ˆï¼ˆæ¨èï¼‰

#### æ–¹æ³•1: Docker Composeï¼ˆæœ€ç®€å•ï¼‰

```bash
# å…è®¸X11æ˜¾ç¤º
xhost +local:docker

# å¯åŠ¨å®¹å™¨
docker-compose up person-detector-amd

# åå°è¿è¡Œ
docker-compose up -d person-detector-amd

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f person-detector-amd

# åœæ­¢
docker-compose down
```

#### æ–¹æ³•2: ç›´æ¥ä½¿ç”¨Docker

```bash
# æ„å»ºé•œåƒ
docker build -t person-detector:amd -f Dockerfile .

# å…è®¸X11æ˜¾ç¤º
xhost +local:docker

# è¿è¡Œå®¹å™¨
docker run -it --rm \
  --device=/dev/bus/usb \
  --env="DISPLAY=$DISPLAY" \
  --volume="/tmp/.X11-unix:/tmp/.X11-unix:rw" \
  --volume="$PWD:/workspace" \
  person-detector:amd \
  person_detect.py --engine onnx-openvino --benchmark
```

### NVIDIA GPUæ–¹æ¡ˆï¼ˆä»…ä¾›å‚è€ƒï¼‰

```bash
# æ„å»ºé•œåƒ
docker build -t person-detector:nvidia -f Dockerfile.nvidia .

# è¿è¡Œå®¹å™¨ï¼ˆéœ€è¦nvidia-container-toolkitï¼‰
docker run -it --rm \
  --gpus all \
  --device=/dev/bus/usb \
  --env="DISPLAY=$DISPLAY" \
  --volume="/tmp/.X11-unix:/tmp/.X11-unix:rw" \
  --volume="$PWD:/workspace" \
  person-detector:nvidia \
  person_detect.py --engine pytorch --benchmark
```

### Dockerå‘½ä»¤è¯´æ˜

| å‚æ•° | è¯´æ˜ |
|-----|-----|
| `--device=/dev/bus/usb` | æ˜ å°„USBè®¾å¤‡ï¼ˆBerxelç›¸æœºï¼‰ |
| `--env="DISPLAY=$DISPLAY"` | ä¼ é€’æ˜¾ç¤ºç¯å¢ƒå˜é‡ |
| `--volume="/tmp/.X11-unix:..."` | æ˜ å°„X11 socketï¼ˆç”¨äºæ˜¾ç¤ºçª—å£ï¼‰ |
| `--volume="$PWD:/workspace"` | æ˜ å°„é¡¹ç›®ç›®å½•ï¼ˆå¼€å‘æ¨¡å¼ï¼‰ |
| `--gpus all` | å¯ç”¨GPUï¼ˆä»…NVIDIAï¼‰ |

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ

- **CPU**: AMD Ryzen 9 7940HS
- **GPU**: AMD Radeon 780M
- **RAM**: 32GB DDR5
- **æ¨¡å‹**: YOLOv8n
- **åˆ†è¾¨ç‡**: 1920x1080

### é¢„æœŸæ€§èƒ½

| å¼•æ“ | FP32 FPS | FP16 FPS | åŠ é€Ÿæ¯” |
|------|----------|----------|--------|
| PyTorch (CPU) | 18-22 | - | 1.0x |
| ONNX (CPU) | 22-28 | 25-32 | 1.3-1.5x |
| ONNX + OpenVINO (780M) | - | 30-40 | 1.7-2.0x |

> æ³¨æ„: å®é™…æ€§èƒ½å–å†³äºåœºæ™¯å¤æ‚åº¦ã€æ£€æµ‹æ¡†æ•°é‡ç­‰å› ç´ 

### è¿è¡ŒåŸºå‡†æµ‹è¯•

```bash
# æµ‹è¯•è„šæœ¬ï¼ˆè¿è¡Œ60ç§’ï¼‰
for engine in pytorch onnx onnx-openvino; do
    echo "æµ‹è¯•å¼•æ“: $engine"
    timeout 60 python person_detect.py --engine $engine --benchmark 2>&1 | tail -10
    echo "---"
    sleep 2
done
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1: OpenVINOä¸å¯ç”¨

**ç°è±¡:**
```
âš  OpenVINOæ‰§è¡Œæä¾›å™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU
æç¤º: å®‰è£…OpenVINOæ”¯æŒ: pip install onnxruntime-openvino
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# å®‰è£…OpenVINOæ”¯æŒ
pip install onnxruntime-openvino

# æˆ–ä½¿ç”¨å®˜æ–¹OpenVINOå·¥å…·é“¾
# https://docs.openvino.ai/latest/openvino_docs_install_guides_install_dev_tools.html
```

### é—®é¢˜2: ONNXæ¨¡å‹ä¸å­˜åœ¨

**ç°è±¡:**
```
FileNotFoundError: ONNXæ¨¡å‹ä¸å­˜åœ¨: yolov8n.onnx
è¯·å…ˆè¿è¡Œ: python tools/export_to_onnx.py --model yolov8n.pt --fp16
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# å¯¼å‡ºONNXæ¨¡å‹
python tools/export_to_onnx.py --model yolov8n.pt --fp16
```

### é—®é¢˜3: Dockeræ— æ³•è®¿é—®X11æ˜¾ç¤º

**ç°è±¡:**
```
Cannot connect to X server
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# å…è®¸Dockerè®¿é—®X11
xhost +local:docker

# æˆ–ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼
xhost +local:`docker inspect --format='{{ .Config.Hostname }}' <container_name>`
```

### é—®é¢˜4: USBç›¸æœºæ— æ³•è®¿é—®

**ç°è±¡:**
```
æ— æ³•åˆå§‹åŒ–Berxelç›¸æœº
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥USBè®¾å¤‡
lsusb | grep Berxel

# ç¡®ä¿Dockerå®¹å™¨æœ‰USBè®¿é—®æƒé™
docker run --device=/dev/bus/usb ...

# æ£€æŸ¥udevè§„åˆ™
cat /etc/udev/rules.d/99-berxel.rules
```

### é—®é¢˜5: NVIDIA GPUä¸å¯ç”¨ï¼ˆTensorRTï¼‰

**ç°è±¡:**
```
CUDA error: no kernel image is available for execution
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥NVIDIAé©±åŠ¨
nvidia-smi

# æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version

# ä½¿ç”¨åŒ¹é…çš„TensorRT Dockeré•œåƒ
# ç¡®ä¿TensorRTç‰ˆæœ¬ä¸CUDAç‰ˆæœ¬å…¼å®¹
```

---

## ğŸ“š å‚è€ƒèµ„æº

### AMD 780Mä¼˜åŒ–

- [ONNXRuntime OpenVINOæ‰§è¡Œæä¾›å™¨æ–‡æ¡£](https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html)
- [OpenVINOå·¥å…·å¥—ä»¶](https://docs.openvino.ai/)
- [AMD GPUæ¨ç†ä¼˜åŒ–æŒ‡å—](https://www.amd.com/en/technologies/infinity-hub)

### NVIDIA GPUä¼˜åŒ–ï¼ˆå‚è€ƒï¼‰

- [TensorRTå¼€å‘æŒ‡å—](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [YOLOv8 TensorRTéƒ¨ç½²](https://github.com/ultralytics/ultralytics/blob/main/docs/integrations/tensorrt.md)

### Docker

- [Dockerå®˜æ–¹æ–‡æ¡£](https://docs.docker.com/)
- [Docker Composeæ–‡æ¡£](https://docs.docker.com/compose/)
- [X11 Dockeræ˜¾ç¤ºè½¬å‘](https://wiki.ros.org/docker/Tutorials/GUI)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### 2025-01-08
- âœ… æ·»åŠ ONNXRuntime + OpenVINOæ”¯æŒï¼ˆAMD 780Mä¼˜åŒ–ï¼‰
- âœ… åˆ›å»ºONNXå¯¼å‡ºå·¥å…·
- âœ… æ·»åŠ å¤šæ¨ç†å¼•æ“æ”¯æŒï¼ˆpytorch/onnx/onnx-openvinoï¼‰
- âœ… åˆ›å»ºDockeréƒ¨ç½²æ–¹æ¡ˆï¼ˆAMD/NVIDIAåŒç‰ˆæœ¬ï¼‰
- âœ… æ·»åŠ æ€§èƒ½åŸºå‡†æµ‹è¯•åŠŸèƒ½
- âœ… åˆ›å»ºTensorRTè½¬æ¢è„šæœ¬ï¼ˆNVIDIAå‚è€ƒï¼‰

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

ç‰¹åˆ«å…³æ³¨ï¼š
- AMD 780Må®é™…æ€§èƒ½æµ‹è¯•æ•°æ®
- OpenVINOä¼˜åŒ–é…ç½®
- å…¶ä»–AMD GPUé€‚é…

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚è¯¦è§LICENSEæ–‡ä»¶ã€‚
