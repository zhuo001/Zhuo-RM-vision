# Dockerfile for Berxel P100R Person Detection with TensorRT
# ⚠️ 仅适用于NVIDIA GPU环境
# ⚠️ AMD 780M用户请使用 Dockerfile (ONNXRuntime + OpenVINO)

FROM nvcr.io/nvidia/tensorrt:23.12-py3

# 设置环境变量
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV TZ=Asia/Shanghai

# 创建工作目录
WORKDIR /workspace

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    # 基础工具
    wget \
    curl \
    git \
    # Python工具
    python3-pip \
    # OpenCV依赖
    libopencv-dev \
    python3-opencv \
    libgtk-3-dev \
    # USB相机支持
    libusb-1.0-0-dev \
    v4l-utils \
    # X11显示支持
    libx11-dev \
    libxext-dev \
    x11-apps \
    && rm -rf /var/lib/apt/lists/*

# 升级pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# 安装Python依赖
COPY requirements.txt /tmp/requirements.txt
RUN pip3 install --no-cache-dir -r /tmp/requirements.txt

# 安装TensorRT Python包（如果基础镜像没有）
RUN pip3 install --no-cache-dir tensorrt pycuda || \
    echo "TensorRT already installed in base image"

# 复制项目文件
COPY . /workspace/

# 设置相机设备权限
RUN echo '# Berxel Camera udev rules' > /etc/udev/rules.d/99-berxel.rules && \
    echo 'SUBSYSTEM=="usb", ATTR{idVendor}=="2bc5", MODE="0666"' >> /etc/udev/rules.d/99-berxel.rules

# 暴露可能需要的端口
# EXPOSE 8080

# 设置入口点
ENTRYPOINT ["python3"]
CMD ["person_detect.py", "--help"]

# ===== 使用说明 =====
#
# 构建命令:
#   docker build -t person-detector:nvidia -f Dockerfile.nvidia .
#
# 运行命令（需要NVIDIA GPU + X11显示 + USB设备）:
#   # 允许Docker访问X11显示
#   xhost +local:docker
#
#   # 运行容器（使用NVIDIA Container Toolkit）
#   docker run -it --rm \
#     --gpus all \
#     --device=/dev/bus/usb \
#     --env="DISPLAY=$DISPLAY" \
#     --volume="/tmp/.X11-unix:/tmp/.X11-unix:rw" \
#     --volume="$PWD:/workspace" \
#     person-detector:nvidia \
#     person_detect.py --engine pytorch --benchmark
#
# 使用TensorRT引擎（需先构建）:
#   # 步骤1: 导出ONNX模型
#   docker run -it --rm --gpus all -v "$PWD:/workspace" person-detector:nvidia \
#     tools/export_to_onnx.py --model yolov8n.pt --fp16
#
#   # 步骤2: 构建TensorRT引擎
#   docker run -it --rm --gpus all -v "$PWD:/workspace" person-detector:nvidia \
#     tools/onnx_to_tensorrt.py --onnx yolov8n.onnx --fp16
#
#   # 步骤3: 使用TensorRT推理（需要实现TensorRT推理接口）
#   # 注意: 当前person_detect.py不支持直接加载TensorRT引擎
#
# 说明:
#   --gpus all                      - 启用所有GPU（需要nvidia-container-toolkit）
#   --device=/dev/bus/usb          - 映射USB设备（Berxel相机）
#   --env="DISPLAY=$DISPLAY"        - 传递显示环境变量
#   --volume="/tmp/.X11-unix:..."   - 映射X11 socket
#   --volume="$PWD:/workspace"      - 映射当前目录
#
# 前置要求:
#   1. 安装NVIDIA Container Toolkit:
#      https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
#   
#   2. 验证GPU可用:
#      docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi
